summarise(average_delay = mean(totalDelay, na.rm = TRUE), .groups = 'drop')
ggplot(average_delays, aes(x = as.factor(windy), y = average_delay, fill = origin)) +
geom_boxplot() +
facet_wrap(~ origin) +
labs(title = "Effect of Wind Conditions on Departure Delays by Origin Airport",
x = "Windy (1 = Wind Speed > 25, 0 = Wind Speed <= 25)",
y = "Departure Delay (minutes)",
fill = "Origin Airport") +
scale_fill_manual(values = c("EWR" = "green", "JFK" = "blue", "LGA" = "purple")) +
theme_minimal()
cleaning_flights <- nycflights13::flights %>%
filter(origin == "EWR", !is.na(dep_delay)) %>%
mutate(
dep_delay = ifelse(dep_delay > 15, "late", "on time"),
dep_delay = as.factor(dep_delay),
time_hour = as.Date(time_hour, format = "%Y-%m-%d %H:%M:%S")
) %>%
na.omit() %>%
mutate(across(where(is.character), as.factor))
target_distribution <- cleaning_flights %>%
count(dep_delay) %>%
mutate(proportion = n / sum(n))
target_distribution
set.seed(123123)
data_split <- initial_split(cleaning_flights, prop = 0.9, strata = dep_delay)
train_data <- training(data_split)
test_data <- testing(data_split)
folds <- vfold_cv(train_data, v = 5, strata = dep_delay)
metrics <- metric_set(accuracy, sensitivity, specificity)
flight_recipe <- recipe(dep_delay ~ month + hour + time_hour + carrier, data = train_data) %>%
step_mutate(weekday = wday(time_hour, label = TRUE)) %>%
step_mutate(month = as.factor(month),
hour = as.factor(hour)) %>%
step_rm(time_hour) %>%
step_dummy(all_nominal_predictors()) %>%
step_downsample(dep_delay)
prepared_recipe <- prep(flight_recipe, train_data)
lr_mod <-
logistic_reg(penalty = 1, mixture = 0) %>%
set_engine("glmnet")
lr_wf <-
workflow() %>%
add_recipe(flight_recipe) %>%
add_model(lr_mod)
lr_wf
dt_mod <- decision_tree() %>%
set_engine("rpart") %>%
set_mode("classification")
dt_wf <-
workflow() %>%
add_recipe(flight_recipe) %>%
add_model(dt_mod)
lr_cv <- lr_wf %>%
fit_resamples(folds, metrics = metrics)
library(tidymodels)
library(nycflights13)
library(lubridate)
library(themis)
library(gridExtra)
flights <- nycflights13::flights
airlines_data <- nycflights13::airlines
airports_data <- nycflights13::airports
planes_data <- nycflights13::planes
weather_data <- nycflights13::weather
unique(flights$origin)
EWR_delay_data_hour <- flights %>%
filter(flights$origin == "EWR" & flights$dep_delay > 0) %>%
group_by(hour) %>%
count() %>%
rename(TotalDelays_EWR = n)
EWR_delay_data_hour
EWR_delays_mean <- mean(EWR_delay_data_hour$TotalDelays_EWR)
LGA_delay_data_hour <- flights %>%
filter(flights$origin == "LGA" & flights$dep_delay > 0) %>%
group_by(hour) %>%
count() %>%
rename(TotalDelays_LGA = n)
LGA_delay_data_hour
LGA_delays_mean <- mean(LGA_delay_data_hour$TotalDelays_LGA)
JFK_delay_data_hour <- flights %>%
filter(flights$origin == "JFK" & flights$dep_delay > 0) %>%
group_by(hour) %>%
count() %>%
rename(TotalDelays_JFK = n)
JFK_delay_data_hour
JFK_delays_mean <- mean(JFK_delay_data_hour$TotalDelays_JFK)
plot1.1_EWR <- ggplot(EWR_delay_data_hour, aes(factor(hour), TotalDelays_EWR, fill = factor(hour))) +
geom_col() +
geom_hline(yintercept = EWR_delays_mean, color="black") +
labs(x = "Hour", y = "Delays",
title = "Hour vs Delays (EWR)") +
theme_minimal(base_size = 11) +
theme(legend.position = "none")
plot1.1_LGA <- ggplot(LGA_delay_data_hour, aes(factor(hour), TotalDelays_LGA, fill = factor(hour))) +
geom_col() +
geom_hline(yintercept = LGA_delays_mean, color="black") +
labs(x = "Hour", y = "Delays",
title = "Hour vs Delays (LGA)") +
theme_minimal(base_size = 11) +
theme(legend.position = "none")
plot1.1_JFK <- ggplot(JFK_delay_data_hour, aes(factor(hour), TotalDelays_JFK, fill = factor(hour))) +
geom_col() +
geom_hline(yintercept = JFK_delays_mean, color="black") +
labs(x = "Hour", y = "Delays",
title = "Hour vs Delays (JFK)") +
theme_minimal(base_size = 11) +
theme(legend.position = "none")
plot1.1_EWR
plot1.1_JFK
plot1.1_LGA
grid.arrange(plot1.1_EWR, plot1.1_JFK, plot1.1_LGA, ncol =3)
by_EWR_total <- flights %>%
filter(flights$origin == "EWR" & flights$dep_delay > 0) %>%
group_by(time_hour) %>%
summarise(Total_Flights = n(),
AverageDep_Delay = mean(dep_delay))
by_EWR_total
by_LGA_total <- flights %>%
filter(flights$origin == "LGA" & flights$dep_delay > 0) %>%
group_by(time_hour) %>%
summarise(Total_Flights = n(),
AverageDep_Delay = mean(dep_delay))
by_LGA_total
by_JFK_total <- flights %>%
filter(flights$origin == "JFK" & flights$dep_delay > 0) %>%
group_by(time_hour) %>%
summarise(Total_Flights = n(),
AverageDep_Delay = mean(dep_delay))
by_JFK_total
plot1.2_EWR <- ggplot(by_EWR_total, aes(Total_Flights, AverageDep_Delay)) +
geom_point() +
geom_smooth(method = "lm") + ##gam se adapta melhor aos dados
labs(x = "Total Number of flights", y = "Average Departure Delays",
title = "Total Number of flights vs Average Departure Delays (EWR)") +
theme_minimal()+
theme(legend.position = "none",
plot.title = element_text(hjust = "0.5"))
plot1.2_LGA <- ggplot(by_LGA_total, aes(Total_Flights, AverageDep_Delay)) +
geom_point() +
geom_smooth(method = "lm") +
labs(x = "Total Number of flights", y = "Average Departure Delays",
title = "Total Number of flights vs Average Departure Delays (LGA)") +
theme_minimal()+
theme(legend.position = "none",
plot.title = element_text(hjust = "0.5"))
plot1.2_JFK <- ggplot(by_JFK_total, aes(Total_Flights, AverageDep_Delay)) +
geom_point() +
geom_smooth(method = "lm") +
labs(x = "Total Number of flights", y = "Average Departure Delays",
title = "Total Number of flights vs Average Departure Delays (JFK)") +
theme_minimal()+
theme(legend.position = "none",
plot.title = element_text(hjust = "0.5"))
plot1.2_EWR
plot1.2_JFK
plot1.2_LGA
grid.arrange(plot1.2_EWR, plot1.2_JFK, plot1.2_LGA, ncol=3)
flights_weekday <- flights %>%
mutate(weekday = wday(time_hour, label = TRUE))
average_delays <- flights_weekday %>%
filter(!is.na(dep_delay)) %>%
group_by(origin, weekday) %>%
summarise(average_delay = mean(dep_delay, na.rm = TRUE), .groups = 'drop')
ggplot(average_delays, aes(x = weekday, y = average_delay, fill = origin)) +
geom_col(position = "dodge") +
labs(x = "Weekday", y = "Average Departure Delay (minutes)",
title = "Average Departure Delays by Weekday and Origin") +
theme_minimal()
EWR_delay_data <- flights %>%
filter(flights$origin == "EWR" & flights$dep_delay > 0) %>%
group_by(month) %>%
count() %>%
rename(Month = month, TotalDelays = n)
EWR_delay_data
EWR_delays_mean <- mean(EWR_delay_data$TotalDelays)
LGA_delay_data <- flights %>%
filter(flights$origin == "LGA" & flights$dep_delay > 0) %>%
group_by(month) %>%
count() %>%
rename(Month = month, TotalDelays = n)
LGA_delay_data
LGA_delays_mean <- mean(LGA_delay_data$TotalDelays)
JFK_delay_data <- flights %>%
filter(flights$origin == "JFK" & flights$dep_delay > 0) %>%
group_by(month) %>%
count() %>%
rename(Month = month, TotalDelays = n)
JFK_delay_data
JFK_delays_mean <- mean(JFK_delay_data$TotalDelays)
plot1.3_EWR <- ggplot(EWR_delay_data, aes(factor(Month), TotalDelays, color = factor(Month), group = 2)) +
geom_point() +
geom_line(color = "red") +
geom_hline(yintercept = EWR_delays_mean, color="black") +
#scale_fill_manual(values = c("red", "blue", "green")) we need 12
labs(x="Month", y= "Delays",
title = "Month vs Delays (EWR)") +
theme_minimal(base_size = 11) +
theme(legend.position = "none")
plot1.3_LGA <- ggplot(LGA_delay_data, aes(factor(Month), TotalDelays, color = factor(Month), group = 2)) +
geom_point() +
geom_line(color = "red") +
geom_hline(yintercept = LGA_delays_mean, color="black") +
#scale_fill_manual(values = c("red", "blue", "green")) we need 12
labs(x="Month", y= "Delays",
title = "Month vs Delays (LGA)") +
theme_minimal(base_size = 11) +
theme(legend.position = "none")
plot1.3_JFK <- ggplot(JFK_delay_data, aes(factor(Month), TotalDelays, color = factor(Month), group = 2)) +
geom_point() +
geom_line(color = "red") +
geom_hline(yintercept = JFK_delays_mean, color="black") +
#scale_fill_manual(values = c("red", "blue", "green")) we need 12
labs(x="Month", y= "Delays",
title = "Month vs Delays (JFK)") +
theme_minimal(base_size = 11) +
theme(legend.position = "none")
grid.arrange(plot1.3_EWR, plot1.3_LGA, plot1.3_JFK, ncol=3)
### Bringing the flights data to similar granularity of the weather data
by_time_hour_airport = flights %>%
filter(dep_delay > 0) %>%
group_by(origin, time_hour) %>%
summarise(totalDelay = mean(dep_delay),totalflightsdelayed = n())
merged_fli_weather <- inner_join(by_time_hour_airport, weather_data, by =c("origin","time_hour"))
merged_fli_weather
windy_fli_weather <- merged_fli_weather %>%
mutate(windy = ifelse(wind_speed > 25, 1, 0))
average_delays <- windy_fli_weather %>%
filter(!is.na(totalDelay)) %>%
group_by(origin, time_hour, windy) %>%
summarise(average_delay = mean(totalDelay, na.rm = TRUE), .groups = 'drop')
ggplot(average_delays, aes(x = as.factor(windy), y = average_delay, fill = origin)) +
geom_boxplot() +
facet_wrap(~ origin) +
labs(title = "Effect of Wind Conditions on Departure Delays by Origin Airport",
x = "Windy (1 = Wind Speed > 25, 0 = Wind Speed <= 25)",
y = "Departure Delay (minutes)",
fill = "Origin Airport") +
scale_fill_manual(values = c("EWR" = "green", "JFK" = "blue", "LGA" = "purple")) +
theme_minimal()
cleaning_flights <- nycflights13::flights %>%
filter(origin == "EWR", !is.na(dep_delay)) %>%
mutate(
dep_delay = ifelse(dep_delay > 15, "late", "on time"),
dep_delay = as.factor(dep_delay),
time_hour = as.Date(time_hour, format = "%Y-%m-%d %H:%M:%S")
) %>%
na.omit() %>%
mutate(across(where(is.character), as.factor))
target_distribution <- cleaning_flights %>%
count(dep_delay) %>%
mutate(proportion = n / sum(n))
target_distribution
set.seed(123123)
data_split <- initial_split(cleaning_flights, prop = 0.9, strata = dep_delay)
train_data <- training(data_split)
test_data <- testing(data_split)
folds <- vfold_cv(train_data, v = 5, strata = dep_delay)
metrics <- metric_set(accuracy, sensitivity, specificity)
flight_recipe <- recipe(dep_delay ~ month + hour + time_hour + carrier, data = train_data) %>%
step_mutate(weekday = wday(time_hour, label = TRUE)) %>%
step_mutate(month = as.factor(month),
hour = as.factor(hour)) %>%
step_rm(time_hour) %>%
step_dummy(all_nominal_predictors()) %>%
step_downsample(dep_delay)
prepared_recipe <- prep(flight_recipe, train_data)
lr_mod <-
logistic_reg(penalty = 1, mixture = 0) %>%
set_engine("glmnet")
lr_wf <-
workflow() %>%
add_recipe(flight_recipe) %>%
add_model(lr_mod)
lr_wf
dt_mod <- decision_tree() %>%
set_engine("rpart") %>%
set_mode("classification")
dt_wf <-
workflow() %>%
add_recipe(flight_recipe) %>%
add_model(dt_mod)
lr_cv <- lr_wf %>%
fit_resamples(folds, metrics = metrics)
dt_cv <- dt_wf %>%
fit_resamples(folds, metrics = metrics)
lr_cv %>%
collect_metrics()
dt_cv %>%
collect_metrics()
best_model <- dt_wf %>%
fit(train_data)
best_model %>%
predict(test_data) %>%
bind_cols(test_data %>% select(dep_delay)) %>%
metrics(truth = dep_delay, estimate = .pred_class)
best_model %>%
predict(test_data, type = "prob")
library(tidymodels)
library(modeldata)
library(themis)
attrition <- tibble(attrition)
attrition <- janitor::clean_names(attrition)
str(attrition)
attrition <- attrition |>
mutate(attrition = factor(attrition, levels = c("Yes", "No")))
ggplot(attrition, aes(attrition)) +
geom_bar() +
theme_minimal()
set.seed(123123)
attrition_split <- initial_split(attrition, prop = 0.8, strata = attrition)
at_train <- training(attrition_split)
at_test <- testing(attrition_split)
at_rec <- recipe(attrition ~ ., data = at_train) %>%
step_dummy(all_nominal_predictors()) %>%
step_zv(all_predictors()) %>%
step_corr(all_numeric_predictors()) %>%
step_smote(attrition) #to consider oversampling
at_rec
at_rec %>%
prep() %>%
bake(new_data = NULL)
# Logistic Regression Model
logistic_model <- logistic_reg() %>%
set_engine("glm")
logistic_workflow <- workflow() %>%
add_model(logistic_model) %>%
add_recipe(at_rec)
# Random Forest Model
forest_model <- rand_forest(trees = 50) %>%
set_engine("ranger") %>%
set_mode("classification")
forest_workflow <- workflow() %>%
add_model(forest_model) %>%
add_recipe(at_rec)
set.seed(123123)
attrition_folds <- vfold_cv(at_train, v = 5, strata = attrition)
metrics <- metric_set(accuracy, sens, spec)
logistic_res <- fit_resamples(
logistic_workflow,
resamples = attrition_folds,
metrics = metrics
)
forest_res <- fit_resamples(
forest_workflow,
resamples = attrition_folds,
metrics = metrics
)
logistic_res %>%
collect_metrics()
forest_res %>%
collect_metrics()
best_model <- logistic_workflow %>% fit(at_train)
final_fit <- best_model %>%
predict(at_test) %>%
bind_cols(at_test) %>%
conf_mat(truth= attrition, estimate = .pred_class)
metrics <- metric_set(sens, yardstick::spec, accuracy)
best_model %>%
predict(at_test) %>%
bind_cols(at_test) %>%
metrics(truth = attrition, estimate = .pred_class)
best_model %>%
predict(at_test, type = "prob")
library(tidymodels)
data("diamonds")
diamonds
diamonds |>
ggplot(aes(price)) +
geom_histogram(bins = 20) +
theme_minimal()
diamonds <- diamonds |>
mutate(log_price = log(price))
diamonds |>
ggplot(aes(log_price)) +
geom_histogram(bins = 20) +
theme_minimal()
library(corrr)
diamonds |>
select(where(is.numeric)) |>
correlate() |>
rearrange() |>
shave() |>
rplot()
diamonds |>
ggplot(aes(x, log_price)) +
geom_point() +
geom_smooth() +
theme_minimal()
diamonds |>
filter(x == 0 | y == 0 | z == 0)
diamonds |>
ggplot(aes(carat, log_price)) +
geom_point() +
geom_smooth() +
theme_minimal()
set.seed(44)
d_split <- initial_split(diamonds, prop = 0.9)
d_rec <- recipe(log_price ~ ., training(d_split)) |>
update_role(price, new_role = "original predictor") |>
step_ordinalscore(all_nominal_predictors()) |>
step_rm(x:z) |>
step_sqrt(carat) |>
step_nzv(all_predictors())
d_rec |>
prep() |>
bake(new_data = NULL)
d_rec |>
prep() |>
summary()
rr <- linear_reg(mode = "regression", engine = "glmnet", penalty = 0, mixture = 1)
bt <- boost_tree(mode = "regression") |>
set_engine("xgboost")
d_rr_wf <- workflow() |>
add_recipe(d_rec) |>
add_model(rr)
d_bt_wf <- workflow() |>
add_recipe(d_rec) |>
add_model(bt)
d_wf <- list(d_rr_wf, d_bt_wf)
names(d_wf) <- c("reg_regression", "boosted_trees")
set.seed(11)
folds <- vfold_cv(training(d_split), v = 10)
reg_metrics <- metric_set(mae, rmse, rsq)
d_cv <- lapply(d_wf, \(m) m |> fit_resamples(folds, metrics = reg_metrics) |> collect_metrics())
d_cv
model <- d_bt_wf |>
fit(training(d_split))
model |>
predict(testing(d_split)) |>
bind_cols(testing(d_split)) |>
reg_metrics(truth = log_price, estimate = .pred)
model |>
predict(testing(d_split)) |>
bind_cols(testing(d_split)) |>
ggplot(aes(log_price, .pred)) +
geom_point() +
geom_abline(slope = 1, intercept = 0, color = "red") +
theme_minimal()
model |>
predict(testing(d_split)) |>
bind_cols(testing(d_split)) |>
mutate(price_pred = exp(.pred)) |>
reg_metrics(truth = price, estimate = price_pred)
model |>
predict(testing(d_split)) |>
bind_cols(testing(d_split)) |>
mutate(price_pred = exp(.pred)) |>
ggplot(aes(price, price_pred)) +
geom_point() +
geom_abline(slope = 1, intercept = 0, color = "red") +
theme_minimal()
# Ler os dados
dataset <- read_excel("Passanger_Satisfaction_survey_dataset_LR.xlsx", sheet = "Satisfaction")
# Carregar bibliotecas
library(readxl)
library(dplyr)
library(ggplot2)
library(openxlsx)
library(reshape2)
# Ler os dados
dataset <- read_excel("Passanger_Satisfaction_survey_dataset_LR.xlsx", sheet = "Satisfaction")
setwd("C:/Users/USER/Downloads/Trabalho.OS")
# Ler os dados
dataset <- read_excel("Passanger_Satisfaction_survey_dataset_LR.xlsx", sheet = "Satisfaction")
# Inspecionar os dados
str(dataset)  # Estrutura inicial
summary(dataset)  # Resumo estatístico
# Remover dados ausentes (exemplo: 'Arrival Delay in Minutes')
dataset <- dataset %>%
filter(!is.na(`Arrival Delay in Minutes`))
# Remover a coluna 'satisfaction_v2'
dataset <- dataset %>%
select(-satisfaction_v2)
# Codificar variáveis categóricas para numéricas
dataset <- dataset %>%
mutate(
Gender = ifelse(Gender == "Male", 1, 0),
`Customer Type` = ifelse(`Customer Type` == "Loyal Customer", 1, 0),
`Type of Travel` = ifelse(`Type of Travel` == "Business travel", 1, 0),
Class = case_when(
Class == "Business" ~ 2,
Class == "Eco Plus" ~ 1,
TRUE ~ 0
)
)
# Normalizar variáveis numéricas entre 0 e 1
# Usando `across` para normalizar todas as variáveis numéricas (excluindo `id`)
dataset <- dataset %>%
mutate(across(where(is.numeric), ~ (.-min(.))/(max(.)-min(.)), .names = "normalized_{.col}")) %>%
select(-normalized_id)
# Ordenar os dados por 'id'
dataset <- dataset %>%
arrange(id)
# Salvar o dataset limpo
write.csv(dataset, "Cleaned_Passenger_Satisfaction_Dataset.csv", row.names = FALSE)
# Salvar o dataset limpo
write.csv(dataset, "Cleaned_Passenger_Satisfactionmulti_Dataset.csv", row.names = FALSE)
# Salvar o dataset limpo
write.xlsx(dataset, "Cleaned_Passenger_Satisfactionmulti_Dataset.xlsx", rowNames = FALSE)
write.xlsx(dataset, "Cleaned_Passenger_Satisfactionmulti_Dataset.xlsx", rowNames = FALSE)
# Definir proporção de treino
set.seed(123)  # Para garantir reprodutibilidade (resultados da amostragem sejam sempre os mesmos)
train_indices <- sample(seq_len(nrow(dataset)), size = 0.8 * nrow(dataset))
# Dividir o dataset
train_data <- dataset[train_indices, ]  # 80% para treino
test_data <- dataset[-train_indices, ]  # 20% para teste
# Verificar os tamanhos dos conjuntos
cat("Tamanho do conjunto de treino:", nrow(train_data), "\n")
cat("Tamanho do conjunto de teste:", nrow(test_data), "\n")
# Salvar os conjuntos de treino e teste
write.xlsx(train_data, "Train_Passenger_SatisfactionMulti_Dataset.xlsx", row.names = FALSE)
write.xlsx(test_data, "Test_Passenger_SatisfactionMulti_Dataset.xlsx", row.names = FALSE)
